{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Route efficiency demo\n",
    "\n",
    "This gives a demo of the analysis in the pre-print:\n",
    "[Synthetic route design & assessment using vectors derived from similarity and complexity](https://chemrxiv.org/engage/chemrxiv/article-details/65f0268ce9ebbb4db98a984e)\n",
    "\n",
    "It will use routes extracted from the US patent dataset created for the [PaRoutes](https://github.com/MolecularAI/PaRoutes) benchmark set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: reaction-utils in /projects/mai/users/sgenheden/miniconda/envs/rxn-env/lib/python3.8/site-packages (0.0.1)\n",
      "Collecting rdchiral@ git+https://github.com/connorcoley/rdchiral.git@master\n",
      "  Cloning https://github.com/connorcoley/rdchiral.git (to revision master) to /scratch/kpzn768/pip-install-ni8guwwj/rdchiral_29c467ec6d094df59508ec64de80b753\n",
      "  Running command git clone -q https://github.com/connorcoley/rdchiral.git /scratch/kpzn768/pip-install-ni8guwwj/rdchiral_29c467ec6d094df59508ec64de80b753\n",
      "^C\n",
      "\u001b[31mERROR: Operation cancelled by user\u001b[0m\n",
      "--2024-03-14 10:19:21--  https://zenodo.org/record/7341155/files/ref_routes_n1.json?download=1\n",
      "Resolving proxy.srv.scp (proxy.srv.scp)... 10.96.66.4\n",
      "Connecting to proxy.srv.scp (proxy.srv.scp)|10.96.66.4|:3128... connected.\n",
      "Proxy request sent, awaiting response... 301 MOVED PERMANENTLY\n",
      "Location: /records/7341155/files/ref_routes_n1.json [following]\n",
      "--2024-03-14 10:19:22--  https://zenodo.org/records/7341155/files/ref_routes_n1.json\n",
      "Connecting to proxy.srv.scp (proxy.srv.scp)|10.96.66.4|:3128... connected.\n",
      "Proxy request sent, awaiting response... 200 OK\n",
      "Length: 64187987 (61M) [text/plain]\n",
      "Saving to: ‘ref_routes_n1.json’\n",
      "\n",
      " 3% [>                                      ] 2,224,591    228KB/s  eta 5m 14s "
     ]
    }
   ],
   "source": [
    "#@title Installation -- Run this cell to install rnxutils\n",
    "\n",
    "!pip install reaction-utils\n",
    "!wget https://zenodo.org/record/7341155/files/ref_routes_n1.json?download=1 -O ref_routes_n1.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from rdkit import Chem\n",
    "from rdkit import DataStructs\n",
    "from rdkit.Chem import Descriptors, rdFingerprintGenerator\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from rxnutils.routes.base import SynthesisRoute\n",
    "\n",
    "from complexity import calc_cm_star, calculate_molecular_complexity\n",
    "\n",
    "np.seterr(divide='ignore')\n",
    "sns.set_context(\"paper\", font_scale=1.5)\n",
    "sns.set_style(\"darkgrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in PaRoutes n=1 routes (n = 10,000)\n",
    "\n",
    "Read in the PaRoutes routes from the n=1 set and created route objects from them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ref_routes_n1.json\", \"r\") as fileobj:\n",
    "    route_dicts = json.load(fileobj)\n",
    "routes = [SynthesisRoute(route_dict) for route_dict in route_dicts]\n",
    "len(routes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to chains and pandas Dataframe (n = 42,918)\n",
    "\n",
    "This extracts individual chains from the synthesis routes and put each molecule of such a chain on a row in a pandas DataFrame\n",
    "\n",
    "Uses CM* in the creation of the chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_df(route, project):\n",
    "    chains = route.chains(calc_cm_star)\n",
    "    df = pd.DataFrame([mol for chain in chains for mol in chain])\n",
    "    df[\"project\"] = project\n",
    "    df[\"serial\"] = df[\"project\"] + \"-\" + df[\"serial\"]\n",
    "    df = df[\n",
    "        [\n",
    "            \"project\",\n",
    "            \"serial\",\n",
    "            \"step\",\n",
    "            \"chain\",\n",
    "            \"reaction_id\",\n",
    "            \"smiles\",\n",
    "            \"type\",\n",
    "        ]\n",
    "    ]\n",
    "    return df.rename(\n",
    "        columns={\n",
    "            \"serial\": \"idx\",\n",
    "            \"step\": \"step_id\",\n",
    "            \"smiles\": \"SMILES\",\n",
    "        }\n",
    "    )\n",
    "df = None\n",
    "for idx, route in enumerate(tqdm(routes), 1):\n",
    "    temp_df = make_df(route, f\"USPTO-{idx:06}\")\n",
    "    if df is None:\n",
    "        df = temp_df\n",
    "    else:\n",
    "        df = pd.concat([df, temp_df])\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare last route with the chain that were extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes[-1].image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[df.project==\"USPTO-010000\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select routes with < 3 chains (n = 42,857)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subs = df[(df[\"chain\"] != \"sub1\")&(df[\"chain\"] != \"lls\")]\n",
    "sub2_list = subs.project.tolist()\n",
    "df = df[~df[\"project\"].isin(sub2_list)]\n",
    "\n",
    "subs = df[df[\"chain\"] == \"sub1\"] \n",
    "sub1_list = subs.project.tolist()\n",
    "df = df.assign(linear=np.where(df.project.isin(sub1_list), False, True))\n",
    "\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate descriptors\n",
    "\n",
    "Similarity to target\n",
    "* Morgan r=2 bit vector\n",
    "* Tanimoto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate RDKit mol objects\n",
    "df[\"mol\"] = [Chem.MolFromSmiles(smi) for smi in df[\"SMILES\"]]\n",
    "\n",
    "# Generate Morgan fingerprints with and without counts\n",
    "mfpgen = rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=2048)\n",
    "df[\"morg\"] = [mfpgen.GetFingerprint(mol) for mol in df[\"mol\"]]\n",
    "\n",
    "# Calculate Tanimoto similarity metrics for all chains\n",
    "def calc_similarity(df, fp, metric):\n",
    "    target_fp = df[df[\"type\"]==\"target\"][fp].iloc[0]\n",
    "    return metric(target_fp, df[fp].to_list())\n",
    "\n",
    "tan = df.groupby(\"project\").apply(\n",
    "    calc_similarity, fp=\"morg\", metric=DataStructs.BulkTanimotoSimilarity\n",
    ").explode()\n",
    "df = df.assign(tan=tan.values)\n",
    "\n",
    "# Drop fingerprint columns\n",
    "df = df.drop(columns=[\"morg\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "CSE, CM, and CM*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_complexity(mol):\n",
    "    dict_ = dict(zip([\"CSE\", \"CM\", \"CM*\"], calculate_molecular_complexity(mol)))\n",
    "    return pd.Series(dict_)\n",
    "metrics = df[\"mol\"].apply(calc_complexity)\n",
    "df = df.assign(**metrics.to_dict(orient=\"series\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"CM*\"] = df.SMILES.apply(calc_cm_star)\n",
    "print(df[\"CM*\"].describe())\n",
    "      \n",
    "df[\"nC\"] = (df[\"CM*\"] - df[\"CM*\"].min()) / (df[\"CM*\"].max() - df[\"CM*\"].min())\n",
    "print(df.nC.describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Molecular weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"MW\"] = [Chem.Descriptors.MolWt(mol) for mol in df[\"mol\"]]\n",
    "df[\"MW\"] = df.MW.round(0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove low-MW targets and low complexity mols (eg, isotope labelled targets and erroneous route compilations, n = 42, 854)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# low-MW targets\n",
    "low_mw = (df[\"type\"] == \"target\") & (df[\"MW\"] < 120)\n",
    "df_low_mw = df[low_mw]\n",
    "low_mw_projs = df_low_mw.project.tolist()\n",
    "\n",
    "# low complexity (CM*) SMs or inters\n",
    "\n",
    "low_comp = (df[\"CM*\"] < 2.6)\n",
    "df_low_comp = df[low_comp]\n",
    "low_comp_projs = df_low_comp.project.tolist()\n",
    "\n",
    "remove_list = low_mw_projs + low_comp_projs\n",
    "keep_sel = ~(df[\"project\"].isin(remove_list))\n",
    "df = df[keep_sel]\n",
    "\n",
    "df.reset_index(inplace=True)\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate dx/dy values for required x/y variables\n",
    "\n",
    "This calculates the delta values along the chains for the fingerprints, and the complexity metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"tan\", \"MW\", \"CM*\", \"nC\"]\n",
    "df = df.sort_values(by=[\"project\", \"chain\", \"step_id\"], ignore_index=True)\n",
    "for col in columns:\n",
    "    # Calculate dx and dy values along LLS for each project\n",
    "    df[f\"d_{col}\"] = df.groupby(\"project\")[col].diff().fillna(0)\n",
    "df.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate necessary values to assess vector path real and vector path perfect\n",
    "\n",
    "Will use Tanimoty similarity of bit-vector and nC as the two axis, but this can be changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_var = \"tan\"\n",
    "y_var = \"nC\"\n",
    "\n",
    "df[\"proj_chain\"] = np.where(df[\"chain\"] == \"lls\", df[\"project\"], df[\"project\"] + \"x\")\n",
    "\n",
    "# Generate new dataframes of x_var aggregates and y_var aggregates grouped by project\n",
    "# First and last will return the SM and target for each project\n",
    "data_aggs_x = df.groupby(\"proj_chain\", group_keys=False)[x_var].agg([\"first\", \"last\"])\n",
    "data_aggs_y = df.groupby(\"proj_chain\", group_keys=False)[y_var].agg([\"first\", \"last\"])\n",
    "\n",
    "#  Map summed values from aggregate dataframes to original dataframe\n",
    "# First/last group values used to calculate ranges from SM to target\n",
    "df[\"x_range\"] = df[\"proj_chain\"].map(data_aggs_x[\"last\"]) - df[\"proj_chain\"].map(\n",
    "    data_aggs_x[\"first\"]\n",
    ")\n",
    "df[\"y_range\"] = df[\"proj_chain\"].map(data_aggs_y[\"last\"]) - df[\"proj_chain\"].map(\n",
    "    data_aggs_y[\"first\"]\n",
    ")\n",
    "\n",
    "df[\"vmin\"] = np.sqrt((df[\"x_range\"] ** 2 + df[\"y_range\"] ** 2).astype(float))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scalar projection between the xy vectors and vmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"vector\"] = list(zip(df[\"d_tan\"], df[\"d_nC\"]))\n",
    "df[\"vector_vmin\"] = list(zip(df.x_range, df.y_range))    \n",
    "df[\"sc_pr_vmin\"] = [(np.dot(v1, v2) / np.linalg.norm(v2)) for v1, v2 in list(zip(df.vector, df.vector_vmin)) ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The maximum step count per project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = df.groupby(\"project\")[\"step_id\"].agg([max])\n",
    "df[\"step_max\"] = df[\"project\"].map(targets[\"max\"])\n",
    "df[\"step_max_cat\"] = df[\"step_max\"]\n",
    "df = df.astype({\"step_max_cat\":\"category\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit a polynomial function to the step count versus median vmin\n",
    "\n",
    "This will be used as a function to calculate route efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = []\n",
    "meds = []\n",
    "for i in range(2, df[\"step_max\"].max()+1):\n",
    "    filters = np.where((df[\"step_max\"] == i) & (df[\"type\"] == \"target\"))\n",
    "    dfilt_vmin_iqs = df.loc[filters]\n",
    "\n",
    "    steps.append(i)\n",
    "    meds.append(dfilt_vmin_iqs.vmin.median())\n",
    "    \n",
    "inv_steps = [1/i for i in steps]\n",
    "steps_array = np.array(inv_steps)\n",
    "meds_array = np.array(meds)\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, include_bias=False)\n",
    "poly_features = poly.fit_transform(steps_array.reshape(-1, 1))\n",
    "\n",
    "poly_reg_model = LinearRegression()\n",
    "poly_reg_model.fit(poly_features, meds_array)\n",
    "\n",
    "a = poly_reg_model.coef_[0]\n",
    "b = poly_reg_model.coef_[1]\n",
    "c = poly_reg_model.intercept_\n",
    "\n",
    "df[\"eff_R\"] = df[\"vmin\"] / ((a / df[\"step_id\"]) + ( b / df[\"step_id\"]**2) + c)\n",
    "print(f'Regression formula = a/n + b/n**2 + c')\n",
    "print(f' a = {a}')\n",
    "print(f' b = {b}')\n",
    "print(f' c = {c}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regression coefficient from fitting of litterature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a2 = -0.40330893356344394\n",
    "b2 = -0.009805775251438161\n",
    "c2 = 0.9435001177152702"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.scatterplot(x=steps, y=meds_array)\n",
    "sns.lineplot(x=steps, y=a/np.asarray(steps) + b/np.asarray(steps)**2 + c, label=\"patent\")\n",
    "sns.lineplot(x=steps, y=a2/np.asarray(steps) + b2/np.asarray(steps)**2 + c2, label=\"litt.\").set(xlabel=\"step (LLS)\", ylabel=\"$v_{min}$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the categories for the transformation efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = np.where((df.type != \"sm\") & (df[\"type\"] != \"branch\"))\n",
    "dfilt = df.loc[filters]\n",
    "quantiles = dfilt.sc_pr_vmin.quantile([0.2, 0.4, 0.6, 0.8]).tolist()\n",
    "print(dfilt.sc_pr_vmin.describe(percentiles=[0.2, 0.4, 0.6, 0.8]))\n",
    "\n",
    "df[\"prod_cat\"] = \"v-low\"\n",
    "df.loc[df.sc_pr_vmin>quantiles[0],\"prod_cat\"] = \"low\"\n",
    "df.loc[df.sc_pr_vmin>quantiles[1],\"prod_cat\"] = \"medium\"\n",
    "df.loc[df.sc_pr_vmin>quantiles[2],\"prod_cat\"] = \"high\"\n",
    "df.loc[df.sc_pr_vmin>quantiles[3],\"prod_cat\"] = \"v-high\"\n",
    "df.prod_cat = df.prod_cat.astype({\"prod_cat\": \"category\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting example routes\n",
    "\n",
    "The route index can be set with the `idx` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 5000\n",
    "sel_data = df[df[\"project\"] == f\"USPTO-{idx:06}\"]\n",
    "\n",
    "x_var=\"tan\"\n",
    "y_var=\"nC\"\n",
    "\n",
    "\n",
    "df_tgt = sel_data[sel_data.type==\"target\"]\n",
    "vmin = df_tgt[\"vmin\"].values[0]\n",
    "eff_r = df_tgt[\"eff_R\"].values[0]\n",
    "print(\"Synthetic range = \", vmin)\n",
    "print(\"Route efficiency = \", eff_r)\n",
    "\n",
    "sims = list(sel_data[x_var])\n",
    "comps = list(sel_data[y_var])\n",
    "prods = list(sel_data[\"prod_cat\"])\n",
    "types = list(sel_data[\"type\"])\n",
    "\n",
    "sns.lineplot(\n",
    "    data=sel_data, x=x_var, y=y_var, zorder=1, sort=False, dashes=True\n",
    ")\n",
    "sns.scatterplot(\n",
    "    data=sel_data.iloc[:1],\n",
    "    x=x_var,\n",
    "    y=y_var,\n",
    "    markers={\"sm\":\"s\"},\n",
    "    style=\"type\",\n",
    "    hue=\"type\",\n",
    "    s=60,\n",
    ")\n",
    "\n",
    "sns.scatterplot(\n",
    "    data=sel_data.iloc[1:],\n",
    "    x=x_var,\n",
    "    y=y_var,\n",
    "    #markers={\"sm\":\"s\"},\n",
    "    size=\"prod_cat\",\n",
    "    size_order = [\"v-high\", \"high\", \"medium\", \"low\", \"v-low\"],\n",
    "    sizes = (35, 85),\n",
    "    hue=\"prod_cat\",\n",
    "    hue_order = [\"v-high\", \"high\", \"medium\", \"low\", \"v-low\"],\n",
    "    style = \"prod_cat\",\n",
    "    style_order = [\"v-high\", \"high\", \"medium\", \"low\", \"v-low\"],\n",
    "    markers = {\"v-high\": \"^\", \"high\": \"^\", \"medium\": \"o\", \"low\":\"v\", \"v-low\": \"v\"},   \n",
    "    s=60,\n",
    ").set_xlabel(\"similarity to target (S)\", fontsize=12, fontweight=\"bold\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "routes[idx-1].image()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scoring routes\n",
    "\n",
    "This shows how one could implement a scoring function for a `SynthesisRoute` object\n",
    "\n",
    "First we setup 3 different functions:\n",
    "1. A molecular complexity scorer\n",
    "2. A function that calculates similarities\n",
    "3. A function that calculate V_min50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function calculate the normalized CM*\n",
    "def norm_cm_star(smiles, min_val=3.58, max_val=9.20):\n",
    "    cstar = calc_cm_star(smiles)\n",
    "    return (cstar - min_val) / (max_val - min_val)\n",
    "\n",
    "# This function calculates the Tanimoty similarity between the targets and all the other molecules in the chain\n",
    "def calc_similarities(smiles_list):\n",
    "    rd_mols = [Chem.MolFromSmiles(smi) for smi in smiles_list]\n",
    "    mfpgen = Chem.rdFingerprintGenerator.GetMorganGenerator(radius=2, fpSize=2048)\n",
    "    fps = [mfpgen.GetFingerprint(mol) for mol in rd_mols]\n",
    "    return DataStructs.BulkTanimotoSimilarity(fps[-1], fps)\n",
    "\n",
    "# This function calculate the V_min50\n",
    "def vmin_step_func(nsteps, a = -1.3073, b=1.3267, c=1.0162):\n",
    "    return a/nsteps + b/nsteps**2 + c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This now calculates the efficiency using the three functions above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "route = routes[idx-1]\n",
    "chains = route.chains(norm_cm_star)\n",
    "lls = chains[0]\n",
    "\n",
    "smiles_list = [mol[\"smiles\"] for mol in lls]\n",
    "similarities = calc_similarities(smiles_list)\n",
    "complexities = [mol[\"complexity\"] for mol in lls]\n",
    "\n",
    "synthetic_range = np.sqrt(\n",
    "    (similarities[0] - similarities[-1]) ** 2\n",
    "    + (complexities[0] - complexities[-1]) ** 2\n",
    ")\n",
    "efficiency = synthetic_range / vmin_step_func(len(lls)-1)\n",
    "print(\"Synthetic range = \", synthetic_range)\n",
    "print(\"Route efficiency = \", efficiency)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 ('rxn-env')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c267120ba7edf7c52b72365de3c363711b2eb182e2e34d822e10c2fde56b5194"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
